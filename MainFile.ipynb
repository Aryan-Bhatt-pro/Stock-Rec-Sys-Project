{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 03:37:31.652504: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-04 03:37:32.963160: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pandas_datareader as web\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "#from sklearn.linear_mode\n",
    "#import LinearRegression\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras import Model\n",
    "from keras.layers import Dense, LSTM, Dropout, Concatenateload\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.style.use('fivethirtyeight')\n",
    "#plt.style.use('fivethirtyeight')\n",
    "plt.style.use('seaborn-v0_8-dark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Stocks dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Positve</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Total</th>\n",
       "      <th>NeutralPos</th>\n",
       "      <th>NeutralNeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/2/2017</td>\n",
       "      <td>964.00</td>\n",
       "      <td>952.1201</td>\n",
       "      <td>967.305</td>\n",
       "      <td>2415846</td>\n",
       "      <td>959.19</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10/2/2017</td>\n",
       "      <td>37.088734</td>\n",
       "      <td>7.577268</td>\n",
       "      <td>55.333998</td>\n",
       "      <td>1003</td>\n",
       "      <td>37.088734</td>\n",
       "      <td>14.260219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>958.00</td>\n",
       "      <td>950.3700</td>\n",
       "      <td>963.690</td>\n",
       "      <td>2643484</td>\n",
       "      <td>957.10</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>38.159879</td>\n",
       "      <td>11.085973</td>\n",
       "      <td>50.754148</td>\n",
       "      <td>1326</td>\n",
       "      <td>38.159879</td>\n",
       "      <td>22.348774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/4/2017</td>\n",
       "      <td>954.21</td>\n",
       "      <td>954.0500</td>\n",
       "      <td>967.790</td>\n",
       "      <td>2460721</td>\n",
       "      <td>965.45</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10/4/2017</td>\n",
       "      <td>36.168582</td>\n",
       "      <td>10.727969</td>\n",
       "      <td>53.103448</td>\n",
       "      <td>1305</td>\n",
       "      <td>36.168582</td>\n",
       "      <td>19.641470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/5/2017</td>\n",
       "      <td>970.00</td>\n",
       "      <td>969.6400</td>\n",
       "      <td>981.510</td>\n",
       "      <td>3119487</td>\n",
       "      <td>980.85</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10/5/2017</td>\n",
       "      <td>47.939017</td>\n",
       "      <td>7.227555</td>\n",
       "      <td>44.833427</td>\n",
       "      <td>1771</td>\n",
       "      <td>47.939017</td>\n",
       "      <td>24.411076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/6/2017</td>\n",
       "      <td>975.64</td>\n",
       "      <td>975.6400</td>\n",
       "      <td>995.750</td>\n",
       "      <td>3719840</td>\n",
       "      <td>989.58</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10/6/2017</td>\n",
       "      <td>34.628045</td>\n",
       "      <td>11.586570</td>\n",
       "      <td>53.785385</td>\n",
       "      <td>1519</td>\n",
       "      <td>34.628045</td>\n",
       "      <td>19.818134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>3/5/2018</td>\n",
       "      <td>1494.24</td>\n",
       "      <td>1481.0000</td>\n",
       "      <td>1525.380</td>\n",
       "      <td>5233934</td>\n",
       "      <td>1523.61</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>3/5/2018</td>\n",
       "      <td>38.274182</td>\n",
       "      <td>7.794015</td>\n",
       "      <td>53.931802</td>\n",
       "      <td>1437</td>\n",
       "      <td>38.274182</td>\n",
       "      <td>15.879162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>3/6/2018</td>\n",
       "      <td>1533.20</td>\n",
       "      <td>1528.0000</td>\n",
       "      <td>1542.130</td>\n",
       "      <td>4561718</td>\n",
       "      <td>1537.64</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>3/6/2018</td>\n",
       "      <td>45.234604</td>\n",
       "      <td>6.818182</td>\n",
       "      <td>47.947214</td>\n",
       "      <td>1364</td>\n",
       "      <td>45.234604</td>\n",
       "      <td>20.887916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3/7/2018</td>\n",
       "      <td>1526.52</td>\n",
       "      <td>1522.5100</td>\n",
       "      <td>1545.900</td>\n",
       "      <td>4174123</td>\n",
       "      <td>1545.00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>3/7/2018</td>\n",
       "      <td>38.167260</td>\n",
       "      <td>9.786477</td>\n",
       "      <td>52.046263</td>\n",
       "      <td>1124</td>\n",
       "      <td>38.167260</td>\n",
       "      <td>19.757162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>3/8/2018</td>\n",
       "      <td>1550.00</td>\n",
       "      <td>1545.2500</td>\n",
       "      <td>1554.880</td>\n",
       "      <td>3512528</td>\n",
       "      <td>1551.86</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>3/8/2018</td>\n",
       "      <td>37.221728</td>\n",
       "      <td>8.726625</td>\n",
       "      <td>54.051647</td>\n",
       "      <td>1123</td>\n",
       "      <td>37.221728</td>\n",
       "      <td>16.691926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>3/9/2018</td>\n",
       "      <td>1563.50</td>\n",
       "      <td>1559.0800</td>\n",
       "      <td>1578.940</td>\n",
       "      <td>4417059</td>\n",
       "      <td>1578.89</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>3/9/2018</td>\n",
       "      <td>39.465570</td>\n",
       "      <td>10.996917</td>\n",
       "      <td>49.537513</td>\n",
       "      <td>973</td>\n",
       "      <td>39.465570</td>\n",
       "      <td>23.476353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date     open        low      high   volume    close  Name  \\\n",
       "0    10/2/2017   964.00   952.1201   967.305  2415846   959.19  AMZN   \n",
       "1    10/3/2017   958.00   950.3700   963.690  2643484   957.10  AMZN   \n",
       "2    10/4/2017   954.21   954.0500   967.790  2460721   965.45  AMZN   \n",
       "3    10/5/2017   970.00   969.6400   981.510  3119487   980.85  AMZN   \n",
       "4    10/6/2017   975.64   975.6400   995.750  3719840   989.58  AMZN   \n",
       "..         ...      ...        ...       ...      ...      ...   ...   \n",
       "104   3/5/2018  1494.24  1481.0000  1525.380  5233934  1523.61  AMZN   \n",
       "105   3/6/2018  1533.20  1528.0000  1542.130  4561718  1537.64  AMZN   \n",
       "106   3/7/2018  1526.52  1522.5100  1545.900  4174123  1545.00  AMZN   \n",
       "107   3/8/2018  1550.00  1545.2500  1554.880  3512528  1551.86  AMZN   \n",
       "108   3/9/2018  1563.50  1559.0800  1578.940  4417059  1578.89  AMZN   \n",
       "\n",
       "          Date    Positve   Negative    Neutral  Total  NeutralPos  NeutralNeg  \n",
       "0    10/2/2017  37.088734   7.577268  55.333998   1003   37.088734   14.260219  \n",
       "1    10/3/2017  38.159879  11.085973  50.754148   1326   38.159879   22.348774  \n",
       "2    10/4/2017  36.168582  10.727969  53.103448   1305   36.168582   19.641470  \n",
       "3    10/5/2017  47.939017   7.227555  44.833427   1771   47.939017   24.411076  \n",
       "4    10/6/2017  34.628045  11.586570  53.785385   1519   34.628045   19.818134  \n",
       "..         ...        ...        ...        ...    ...         ...         ...  \n",
       "104   3/5/2018  38.274182   7.794015  53.931802   1437   38.274182   15.879162  \n",
       "105   3/6/2018  45.234604   6.818182  47.947214   1364   45.234604   20.887916  \n",
       "106   3/7/2018  38.167260   9.786477  52.046263   1124   38.167260   19.757162  \n",
       "107   3/8/2018  37.221728   8.726625  54.051647   1123   37.221728   16.691926  \n",
       "108   3/9/2018  39.465570  10.996917  49.537513    973   39.465570   23.476353  \n",
       "\n",
       "[109 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AmazonStock_Sentiment_6M.csv');\n",
    "demo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing general user's decisions in the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decisions_list = []\n",
    "df_decisions_list.append({'df': pd.read_csv('./amazon_stock_trades.csv'), 'comp': 'AMZN'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./apple_stock_trades.csv'), 'comp': 'AAPL'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./cisco_stock_trades.csv'), 'comp': 'CSCO'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./ibm_stock_trades.csv'), 'comp': 'IBM'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./jnj_stock_trades.csv'), 'comp': 'JNJ'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./jnpr_stock_trades.csv'), 'comp': 'JNPR'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./msft_stock_trades.csv'), 'comp': 'MSFT'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./orcl_stock_trades.csv'), 'comp': 'ORCL'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./pfizer_stock_trades.csv'), 'comp': 'PFIZER'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./tgt_stock_trades.csv'), 'comp': 'TGT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale each df\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "columns_to_exclude = ['Sector of stock', 'Buy/Sell/Keep']\n",
    "columns_to_normalize = df_decisions_list[0]['df'].columns.difference(columns_to_exclude)\n",
    "scalers_decisions = []\n",
    "for i in range(len(df_decisions_list)):\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_values = scaler.fit_transform(df_decisions_list[i]['df'][columns_to_normalize])\n",
    "    normalized_df = pd.DataFrame(normalized_values, columns=columns_to_normalize)\n",
    "    scalers_decisions.append({'scaler': scaler, 'comp': df_decisions_list[i]['comp']})\n",
    "\n",
    "    # Concatenate the normalized DataFrame with the excluded column\n",
    "    df_decisions_list[i]['df'] = pd.concat([normalized_df, df_decisions_list[i]['df'][columns_to_exclude]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'scaler': MinMaxScaler(), 'comp': 'AMZN'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'AAPL'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'CSCO'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'IBM'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'JNJ'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'JNPR'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'MSFT'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'ORCL'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'PFIZER'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'TGT'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalers_decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalers for stock data\n",
    "\n",
    "# create main_df for each company stock data\n",
    "main_df = []\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AmazonStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'AMZN'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AAPLStock_sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'AAPL'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/CSCOStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'CSCO'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/IBMStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'IBM'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/JNJStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'JNJ'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/JNPRStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'JNPR'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/MSFTStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'MSFT'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/ORCLStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'ORCL'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/PfizerStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'PFIZER'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/TGTStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'TGT'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in main_df:\n",
    "    i['df']['diff']=i['df']['high']-i['df']['low']\n",
    "for i in main_df:\n",
    "    i['df']['exp']=(i['df']['open']+i['df']['close'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers_stock = []\n",
    "for i in range(len(main_df)):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    main_df[i]['df'][main_df[i]['df'].columns] = scaler.fit_transform(main_df[i]['df'][main_df[i]['df'].columns])\n",
    "    scalers_stock.append({'scaler': scaler, 'comp': main_df[i]['comp']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01690875490077537 0.0573411800211275 0.0 ... 0.3636736817142966 'IT'\n",
      "  'Keep']\n",
      " [0.006545881621444094 0.06051003470650517 0.003842394418416717 ...\n",
      "  0.27024876293661004 'IT' 'Keep']\n",
      " [0.0 0.04640108646446504 0.030124035188243692 ... 0.3181724276875074\n",
      "  'IT' 'Buy']\n",
      " ...\n",
      " [0.8417116742833404 0.9428571428571434 0.7736249734550866 ...\n",
      "  0.4615521483751204 'Consumer Discretionary' 'Keep']\n",
      " [0.8201080182800169 0.2527472527472538 0.6982374177107671 ...\n",
      "  0.27599163606338406 'Consumer Discretionary' 'Sell']\n",
      " [0.6875778977980893 0.44395604395604266 0.6704183478445533 ...\n",
      "  0.48975352837157216 'Consumer Discretionary' 'Keep']]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for i in df_decisions_list:\n",
    "    dataset.append(i['df'].values)\n",
    "dataset = np.concatenate(dataset, axis = 0)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('stock_decisions.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Current Value of Stock', 'Expected Value of Stock', 'Error in expected value of stock', 'Percentage of portfolio', 'Percentage of sector', 'Positive', 'Negative', 'Neutral', 'Total', 'Neutral_Pos', 'Neutral_Neg', 'Sector of stock','Buy/Sell/Keep'])\n",
    "    writer.writerows(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Value of Stock</th>\n",
       "      <th>Expected Value of Stock</th>\n",
       "      <th>Error in expected value of stock</th>\n",
       "      <th>Percentage of portfolio</th>\n",
       "      <th>Percentage of sector</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Total</th>\n",
       "      <th>Neutral_Pos</th>\n",
       "      <th>Neutral_Neg</th>\n",
       "      <th>Sector of stock</th>\n",
       "      <th>Buy/Sell/Keep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016909</td>\n",
       "      <td>0.057341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393651</td>\n",
       "      <td>0.209993</td>\n",
       "      <td>0.288915</td>\n",
       "      <td>0.354623</td>\n",
       "      <td>0.747695</td>\n",
       "      <td>0.353394</td>\n",
       "      <td>0.634112</td>\n",
       "      <td>0.363674</td>\n",
       "      <td>IT</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.060510</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.618285</td>\n",
       "      <td>0.282692</td>\n",
       "      <td>0.499607</td>\n",
       "      <td>0.399351</td>\n",
       "      <td>0.875622</td>\n",
       "      <td>0.132926</td>\n",
       "      <td>0.659470</td>\n",
       "      <td>0.270249</td>\n",
       "      <td>IT</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046401</td>\n",
       "      <td>0.030124</td>\n",
       "      <td>0.595365</td>\n",
       "      <td>0.277965</td>\n",
       "      <td>0.429087</td>\n",
       "      <td>0.316199</td>\n",
       "      <td>0.038742</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.612328</td>\n",
       "      <td>0.318172</td>\n",
       "      <td>IT</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027272</td>\n",
       "      <td>0.108571</td>\n",
       "      <td>0.042233</td>\n",
       "      <td>0.371262</td>\n",
       "      <td>0.382849</td>\n",
       "      <td>0.553326</td>\n",
       "      <td>0.807705</td>\n",
       "      <td>0.334854</td>\n",
       "      <td>0.926111</td>\n",
       "      <td>0.890981</td>\n",
       "      <td>0.149471</td>\n",
       "      <td>IT</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037013</td>\n",
       "      <td>0.039837</td>\n",
       "      <td>0.058251</td>\n",
       "      <td>0.650335</td>\n",
       "      <td>0.326131</td>\n",
       "      <td>0.433689</td>\n",
       "      <td>0.251870</td>\n",
       "      <td>0.165370</td>\n",
       "      <td>0.620705</td>\n",
       "      <td>0.575857</td>\n",
       "      <td>0.332083</td>\n",
       "      <td>IT</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Current Value of Stock  Expected Value of Stock  \\\n",
       "0                0.016909                 0.057341   \n",
       "1                0.006546                 0.060510   \n",
       "2                0.000000                 0.046401   \n",
       "3                0.027272                 0.108571   \n",
       "4                0.037013                 0.039837   \n",
       "\n",
       "   Error in expected value of stock  Percentage of portfolio  \\\n",
       "0                          0.000000                 0.393651   \n",
       "1                          0.003842                 0.618285   \n",
       "2                          0.030124                 0.595365   \n",
       "3                          0.042233                 0.371262   \n",
       "4                          0.058251                 0.650335   \n",
       "\n",
       "   Percentage of sector  Positive  Negative   Neutral     Total  Neutral_Pos  \\\n",
       "0              0.209993  0.288915  0.354623  0.747695  0.353394     0.634112   \n",
       "1              0.282692  0.499607  0.399351  0.875622  0.132926     0.659470   \n",
       "2              0.277965  0.429087  0.316199  0.038742  0.334798     0.612328   \n",
       "3              0.382849  0.553326  0.807705  0.334854  0.926111     0.890981   \n",
       "4              0.326131  0.433689  0.251870  0.165370  0.620705     0.575857   \n",
       "\n",
       "   Neutral_Neg Sector of stock Buy/Sell/Keep  \n",
       "0     0.363674              IT          Keep  \n",
       "1     0.270249              IT          Keep  \n",
       "2     0.318172              IT           Buy  \n",
       "3     0.149471              IT          Sell  \n",
       "4     0.332083              IT           Buy  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decisions = pd.read_csv('./stock_decisions.csv');\n",
    "df_decisions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decisions.drop('Sector of stock', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking Input from the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Percentage of portfolio': 0.5,\n",
       "  'Percentage of sector': 15.56,\n",
       "  'Sector of Stock': 'IT',\n",
       "  'comp': 'AMZN'},\n",
       " {'Percentage of portfolio': 4.5,\n",
       "  'Percentage of sector': 7.8,\n",
       "  'Sector of Stock': 'IT',\n",
       "  'comp': 'MSFT'},\n",
       " {'Percentage of portfolio': 7.5,\n",
       "  'Percentage of sector': 18.26,\n",
       "  'Sector of Stock': 'Health',\n",
       "  'comp': 'AAPL'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = []\n",
    "\n",
    "todays_date = '1/5/2018'\n",
    "list_of_stocks = []\n",
    "list_of_stocks.append({'Percentage of portfolio': 0.5, 'Percentage of sector': 15.56, 'Sector of Stock': 'IT', 'comp': 'AMZN'});\n",
    "list_of_stocks.append({'Percentage of portfolio': 4.5, 'Percentage of sector': 7.8, 'Sector of Stock': 'IT', 'comp': 'MSFT'});\n",
    "list_of_stocks.append({'Percentage of portfolio': 7.5, 'Percentage of sector': 18.26, 'Sector of Stock': 'Health', 'comp': 'AAPL'});\n",
    "list_of_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError, MeanSquaredError\n",
    "from keras.layers import Dense, LSTM, Dropout, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "@register_keras_serializable(package=\"MyLoss\")\n",
    "def MyLoss(y_true, y_pred):\n",
    "    msle = MeanSquaredLogarithmicError()(y_true[:,0], y_pred[:,0])\n",
    "    mse = MeanSquaredError()(y_true[:,1],y_pred[:,1])\n",
    "    return  msle + mse\n",
    "\n",
    "@register_keras_serializable(package='MyModel')\n",
    "class MyModel(Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.lstm1 = LSTM(units=50, return_sequences=True,\n",
    "                          input_shape=[None,30,13])\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.dropout1 = Dropout(0.2)\n",
    "\n",
    "        self.lstm2 = LSTM(units=60, return_sequences=True)\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.dropout2 = Dropout(0.3)\n",
    "\n",
    "        self.lstm3 = LSTM(units=70, return_sequences=True)\n",
    "        self.bn3 = BatchNormalization()\n",
    "        self.dropout3 = Dropout(0.4)\n",
    "\n",
    "        self.lstm4 = LSTM(units=80)\n",
    "        self.bn4 = BatchNormalization()\n",
    "        self.dropout4 = Dropout(0.5)\n",
    "\n",
    "        self.dense1_1 = Dense(20)\n",
    "        self.dense2_1 = Dense(1)\n",
    "\n",
    "        self.dense1_2 = Dense(20)\n",
    "        self.dense2_2 = Dense(1)\n",
    "        self.concat = Concatenate(axis=-1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        enc = self.lstm1(inputs)\n",
    "        enc = self.bn1(enc)\n",
    "        enc = self.dropout1(enc)\n",
    "\n",
    "        enc = self.lstm2(enc)\n",
    "        enc = self.bn2(enc)\n",
    "        enc = self.dropout2(enc)\n",
    "\n",
    "        enc = self.lstm3(enc)\n",
    "        enc = self.bn3(enc)\n",
    "        enc = self.dropout3(enc)\n",
    "\n",
    "        enc = self.lstm4(enc)\n",
    "        enc = self.bn4(enc)\n",
    "        enc = self.dropout4(enc)\n",
    "\n",
    "        out1 = self.dense1_1(enc)\n",
    "        out1 = self.dense2_1(out1)\n",
    "\n",
    "        out2 = self.dense1_2(enc)\n",
    "        out2 = self.dense2_2(out2)\n",
    "\n",
    "        out = self.concat([out1, out2])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "def makeNextDayVector(filtered_df, todays_date, stock, comp_name):\n",
    "\n",
    "\n",
    "    filtered_df['diff']=filtered_df['high']-filtered_df['low']\n",
    "    filtered_df['exp']=(filtered_df['open']+filtered_df['close'])/2\n",
    "\n",
    "\n",
    "    loaded_model = load_model('model.keras')\n",
    "\n",
    "    curr_row = filtered_df[filtered_df['Date'] == todays_date]\n",
    "    curr_row.drop(['date', 'Date', 'Name'], axis=1, inplace=True)\n",
    "    filtered_df.drop(['date', 'Date', 'Name'], axis=1, inplace=True)\n",
    "    curr_stock_value = curr_row['open'].iloc[0]\n",
    "\n",
    "    # find scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    for dict in scalers_stock:\n",
    "        if dict['comp'] == comp_name:\n",
    "            scaler = dict['scaler']\n",
    "            break\n",
    "\n",
    "    filtered_df[filtered_df.columns] = scaler.fit_transform(filtered_df[filtered_df.columns])\n",
    "\n",
    "    predicted_values = pd.DataFrame()\n",
    "\n",
    "    predicted_values[['open', 'high', 'low', 'volume', 'close', 'Positve', 'Negative','Neutral', 'Total', 'NeutralPos', 'NeutralNeg']] = 0\n",
    "\n",
    "    predicted_values[['diff', 'exp']] = loaded_model.predict(np.array([filtered_df.values]).astype(float))\n",
    "\n",
    "    # predicted_values=scaler.inverse_transform(predicted_values)\n",
    "    print(predicted_values.columns)\n",
    "\n",
    "    predicted_values[predicted_values.columns] = scaler.inverse_transform(predicted_values)\n",
    "\n",
    "\n",
    "\n",
    "    predicted_values.drop(['open', 'high', 'low', 'volume', 'close', 'Positve', 'Negative','Neutral', 'Total', 'NeutralPos', 'NeutralNeg'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    expected_value = predicted_values['exp'].iloc[0]\n",
    "    error = predicted_values['diff'].iloc[0]\n",
    "\n",
    "    percen_portfolio = stock['Percentage of portfolio']\n",
    "    percen_sector = stock['Percentage of sector']\n",
    "    sector = stock['Sector of Stock']\n",
    "\n",
    "    positives = curr_row['Positve'].iloc[0]\n",
    "    negatives = curr_row['Negative'].iloc[0]\n",
    "    total = curr_row['Total'].iloc[0]\n",
    "    neutral = curr_row['Neutral'].iloc[0]\n",
    "    neutral_pos = curr_row['NeutralPos'].iloc[0]\n",
    "    neutral_neg = curr_row['NeutralNeg'].iloc[0]\n",
    "\n",
    "\n",
    "\n",
    "    stock_vect = []\n",
    "    stock_vect.append(curr_stock_value)\n",
    "    stock_vect.append(expected_value)\n",
    "    stock_vect.append(error)\n",
    "    stock_vect.append(percen_portfolio)\n",
    "    stock_vect.append(percen_sector)\n",
    "    stock_vect.append(positives)\n",
    "    stock_vect.append(negatives)\n",
    "    stock_vect.append(total)\n",
    "    stock_vect.append(neutral)\n",
    "    stock_vect.append(neutral_pos)\n",
    "    stock_vect.append(neutral_neg)\n",
    "\n",
    "    # add posi negi from filtered data in stock vector\n",
    "\n",
    "    # stock_vect.append(sector)\n",
    "\n",
    "\n",
    "    return stock_vect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 03:37:34.590963: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-04 03:37:34.591465: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/aryanbhatt1812/anaconda3/envs/RecSys/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_311081/2375735888.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_row.drop(['date', 'Date', 'Name'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step\n",
      "Index(['open', 'high', 'low', 'volume', 'close', 'Positve', 'Negative',\n",
      "       'Neutral', 'Total', 'NeutralPos', 'NeutralNeg', 'diff', 'exp'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryanbhatt1812/anaconda3/envs/RecSys/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/tmp/ipykernel_311081/2375735888.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_row.drop(['date', 'Date', 'Name'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460ms/step\n",
      "Index(['open', 'high', 'low', 'volume', 'close', 'Positve', 'Negative',\n",
      "       'Neutral', 'Total', 'NeutralPos', 'NeutralNeg', 'diff', 'exp'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryanbhatt1812/anaconda3/envs/RecSys/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/tmp/ipykernel_311081/2375735888.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_row.drop(['date', 'Date', 'Name'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
      "Index(['open', 'high', 'low', 'volume', 'close', 'Positve', 'Negative',\n",
      "       'Neutral', 'Total', 'NeutralPos', 'NeutralNeg', 'diff', 'exp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "next_vectors = []\n",
    "for i in range(len(list_of_stocks)):\n",
    "    if(list_of_stocks[i]['comp'] == 'AMZN'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AmazonStock_Sentiment_6M.csv');\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'AMZN'), 'comp': 'AMZN'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'AAPL'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AAPLStock_sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'AAPL'), 'comp': 'AAPL'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'MSFT'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/MSFTStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'MSFT'), 'comp': 'MSFT'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'PFIZER'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/PfizerStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'PFIZER'), 'comp': 'PFIZER'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1217.51,\n",
       " 1395.839195690751,\n",
       " 25.248018814325256,\n",
       " 0.5,\n",
       " 15.56,\n",
       " 52.54403131,\n",
       " 6.653620352,\n",
       " 1022,\n",
       " 40.80234834,\n",
       " 52.54403131,\n",
       " 27.86822061]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_vectors[0]['next_day_vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Value of Stock</th>\n",
       "      <th>Expected Value of Stock</th>\n",
       "      <th>Error in expected value of stock</th>\n",
       "      <th>Percentage of portfolio</th>\n",
       "      <th>Percentage of sector</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Total</th>\n",
       "      <th>Neutral_Pos</th>\n",
       "      <th>Neutral_Neg</th>\n",
       "      <th>Buy/Sell/Keep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016909</td>\n",
       "      <td>0.057341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393651</td>\n",
       "      <td>0.209993</td>\n",
       "      <td>0.288915</td>\n",
       "      <td>0.354623</td>\n",
       "      <td>0.747695</td>\n",
       "      <td>0.353394</td>\n",
       "      <td>0.634112</td>\n",
       "      <td>0.363674</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.060510</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.618285</td>\n",
       "      <td>0.282692</td>\n",
       "      <td>0.499607</td>\n",
       "      <td>0.399351</td>\n",
       "      <td>0.875622</td>\n",
       "      <td>0.132926</td>\n",
       "      <td>0.659470</td>\n",
       "      <td>0.270249</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046401</td>\n",
       "      <td>0.030124</td>\n",
       "      <td>0.595365</td>\n",
       "      <td>0.277965</td>\n",
       "      <td>0.429087</td>\n",
       "      <td>0.316199</td>\n",
       "      <td>0.038742</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.612328</td>\n",
       "      <td>0.318172</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027272</td>\n",
       "      <td>0.108571</td>\n",
       "      <td>0.042233</td>\n",
       "      <td>0.371262</td>\n",
       "      <td>0.382849</td>\n",
       "      <td>0.553326</td>\n",
       "      <td>0.807705</td>\n",
       "      <td>0.334854</td>\n",
       "      <td>0.926111</td>\n",
       "      <td>0.890981</td>\n",
       "      <td>0.149471</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037013</td>\n",
       "      <td>0.039837</td>\n",
       "      <td>0.058251</td>\n",
       "      <td>0.650335</td>\n",
       "      <td>0.326131</td>\n",
       "      <td>0.433689</td>\n",
       "      <td>0.251870</td>\n",
       "      <td>0.165370</td>\n",
       "      <td>0.620705</td>\n",
       "      <td>0.575857</td>\n",
       "      <td>0.332083</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Current Value of Stock  Expected Value of Stock  \\\n",
       "0                0.016909                 0.057341   \n",
       "1                0.006546                 0.060510   \n",
       "2                0.000000                 0.046401   \n",
       "3                0.027272                 0.108571   \n",
       "4                0.037013                 0.039837   \n",
       "\n",
       "   Error in expected value of stock  Percentage of portfolio  \\\n",
       "0                          0.000000                 0.393651   \n",
       "1                          0.003842                 0.618285   \n",
       "2                          0.030124                 0.595365   \n",
       "3                          0.042233                 0.371262   \n",
       "4                          0.058251                 0.650335   \n",
       "\n",
       "   Percentage of sector  Positive  Negative   Neutral     Total  Neutral_Pos  \\\n",
       "0              0.209993  0.288915  0.354623  0.747695  0.353394     0.634112   \n",
       "1              0.282692  0.499607  0.399351  0.875622  0.132926     0.659470   \n",
       "2              0.277965  0.429087  0.316199  0.038742  0.334798     0.612328   \n",
       "3              0.382849  0.553326  0.807705  0.334854  0.926111     0.890981   \n",
       "4              0.326131  0.433689  0.251870  0.165370  0.620705     0.575857   \n",
       "\n",
       "   Neutral_Neg Buy/Sell/Keep  \n",
       "0     0.363674          Keep  \n",
       "1     0.270249          Keep  \n",
       "2     0.318172           Buy  \n",
       "3     0.149471          Sell  \n",
       "4     0.332083           Buy  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decisions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# columns_to_normalize = df_decisions.columns.difference(['Buy/Sell/Keep'])\n",
    "# normalized_values = scaler.fit_transform(df_decisions[columns_to_normalize])\n",
    "# normalized_df_decisions = pd.DataFrame(normalized_values, columns=columns_to_normalize)\n",
    "# normalized_df_decisions = pd.concat([normalized_df_decisions, df_decisions['Buy/Sell/Keep']], axis=1)\n",
    "# normalized_df_decisions\n",
    "# normalized_df_decisions = pd.DataFrame(scaler.fit_transform(df_decisions), columns=columns_to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_311081/280646284.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  buy_df.drop(columns=['Buy/Sell/Keep'], inplace=True)\n",
      "/tmp/ipykernel_311081/280646284.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sell_df.drop(columns=['Buy/Sell/Keep'], inplace=True)\n",
      "/tmp/ipykernel_311081/280646284.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  keep_df.drop(columns=['Buy/Sell/Keep'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# make but keep and sell dfs\n",
    "\n",
    "# buy df\n",
    "buy_df = df_decisions[df_decisions['Buy/Sell/Keep'] == 'Buy']\n",
    "\n",
    "sell_df = df_decisions[df_decisions['Buy/Sell/Keep'] == 'Sell']\n",
    "\n",
    "keep_df = df_decisions[df_decisions['Buy/Sell/Keep'] == 'Keep']\n",
    "\n",
    "buy_df.drop(columns=['Buy/Sell/Keep'], inplace=True)\n",
    "sell_df.drop(columns=['Buy/Sell/Keep'], inplace=True)\n",
    "keep_df.drop(columns=['Buy/Sell/Keep'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Value of Stock</th>\n",
       "      <th>Expected Value of Stock</th>\n",
       "      <th>Error in expected value of stock</th>\n",
       "      <th>Percentage of portfolio</th>\n",
       "      <th>Percentage of sector</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Total</th>\n",
       "      <th>Neutral_Pos</th>\n",
       "      <th>Neutral_Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016909</td>\n",
       "      <td>0.057341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393651</td>\n",
       "      <td>0.209993</td>\n",
       "      <td>0.288915</td>\n",
       "      <td>0.354623</td>\n",
       "      <td>0.747695</td>\n",
       "      <td>0.353394</td>\n",
       "      <td>0.634112</td>\n",
       "      <td>0.363674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.060510</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.618285</td>\n",
       "      <td>0.282692</td>\n",
       "      <td>0.499607</td>\n",
       "      <td>0.399351</td>\n",
       "      <td>0.875622</td>\n",
       "      <td>0.132926</td>\n",
       "      <td>0.659470</td>\n",
       "      <td>0.270249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.067410</td>\n",
       "      <td>0.091527</td>\n",
       "      <td>0.057948</td>\n",
       "      <td>0.459654</td>\n",
       "      <td>0.264011</td>\n",
       "      <td>0.191714</td>\n",
       "      <td>0.112700</td>\n",
       "      <td>0.163465</td>\n",
       "      <td>0.959393</td>\n",
       "      <td>0.496957</td>\n",
       "      <td>0.460825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.073335</td>\n",
       "      <td>0.023276</td>\n",
       "      <td>0.059970</td>\n",
       "      <td>0.356246</td>\n",
       "      <td>0.273914</td>\n",
       "      <td>0.168752</td>\n",
       "      <td>0.210784</td>\n",
       "      <td>0.379841</td>\n",
       "      <td>0.060957</td>\n",
       "      <td>0.552564</td>\n",
       "      <td>0.445859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.064008</td>\n",
       "      <td>0.077863</td>\n",
       "      <td>0.069635</td>\n",
       "      <td>0.618348</td>\n",
       "      <td>0.294846</td>\n",
       "      <td>0.443775</td>\n",
       "      <td>0.309765</td>\n",
       "      <td>0.330739</td>\n",
       "      <td>0.747575</td>\n",
       "      <td>0.608680</td>\n",
       "      <td>0.313993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>0.777316</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.826290</td>\n",
       "      <td>0.578050</td>\n",
       "      <td>0.158835</td>\n",
       "      <td>0.404228</td>\n",
       "      <td>0.420627</td>\n",
       "      <td>0.564369</td>\n",
       "      <td>0.700073</td>\n",
       "      <td>0.576933</td>\n",
       "      <td>0.380911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.604396</td>\n",
       "      <td>0.928010</td>\n",
       "      <td>0.294132</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.204860</td>\n",
       "      <td>0.548578</td>\n",
       "      <td>0.570575</td>\n",
       "      <td>0.228781</td>\n",
       "      <td>0.670365</td>\n",
       "      <td>0.440210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>0.895305</td>\n",
       "      <td>0.470330</td>\n",
       "      <td>0.850074</td>\n",
       "      <td>0.419840</td>\n",
       "      <td>0.137218</td>\n",
       "      <td>0.205120</td>\n",
       "      <td>0.347657</td>\n",
       "      <td>0.173859</td>\n",
       "      <td>0.665147</td>\n",
       "      <td>0.383629</td>\n",
       "      <td>0.614365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>0.841712</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.773625</td>\n",
       "      <td>0.683732</td>\n",
       "      <td>0.274436</td>\n",
       "      <td>0.373375</td>\n",
       "      <td>0.200784</td>\n",
       "      <td>0.456054</td>\n",
       "      <td>0.807529</td>\n",
       "      <td>0.416400</td>\n",
       "      <td>0.461552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>0.687578</td>\n",
       "      <td>0.443956</td>\n",
       "      <td>0.670418</td>\n",
       "      <td>0.690154</td>\n",
       "      <td>0.341165</td>\n",
       "      <td>0.347666</td>\n",
       "      <td>0.148356</td>\n",
       "      <td>0.043862</td>\n",
       "      <td>0.383637</td>\n",
       "      <td>0.378117</td>\n",
       "      <td>0.489754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Current Value of Stock  Expected Value of Stock  \\\n",
       "0                   0.016909                 0.057341   \n",
       "1                   0.006546                 0.060510   \n",
       "5                   0.067410                 0.091527   \n",
       "6                   0.073335                 0.023276   \n",
       "7                   0.064008                 0.077863   \n",
       "...                      ...                      ...   \n",
       "1059                0.777316                 0.457143   \n",
       "1062                0.903199                 0.604396   \n",
       "1064                0.895305                 0.470330   \n",
       "1067                0.841712                 0.942857   \n",
       "1069                0.687578                 0.443956   \n",
       "\n",
       "      Error in expected value of stock  Percentage of portfolio  \\\n",
       "0                             0.000000                 0.393651   \n",
       "1                             0.003842                 0.618285   \n",
       "5                             0.057948                 0.459654   \n",
       "6                             0.059970                 0.356246   \n",
       "7                             0.069635                 0.618348   \n",
       "...                                ...                      ...   \n",
       "1059                          0.826290                 0.578050   \n",
       "1062                          0.928010                 0.294132   \n",
       "1064                          0.850074                 0.419840   \n",
       "1067                          0.773625                 0.683732   \n",
       "1069                          0.670418                 0.690154   \n",
       "\n",
       "      Percentage of sector  Positive  Negative   Neutral     Total  \\\n",
       "0                 0.209993  0.288915  0.354623  0.747695  0.353394   \n",
       "1                 0.282692  0.499607  0.399351  0.875622  0.132926   \n",
       "5                 0.264011  0.191714  0.112700  0.163465  0.959393   \n",
       "6                 0.273914  0.168752  0.210784  0.379841  0.060957   \n",
       "7                 0.294846  0.443775  0.309765  0.330739  0.747575   \n",
       "...                    ...       ...       ...       ...       ...   \n",
       "1059              0.158835  0.404228  0.420627  0.564369  0.700073   \n",
       "1062              0.184211  0.204860  0.548578  0.570575  0.228781   \n",
       "1064              0.137218  0.205120  0.347657  0.173859  0.665147   \n",
       "1067              0.274436  0.373375  0.200784  0.456054  0.807529   \n",
       "1069              0.341165  0.347666  0.148356  0.043862  0.383637   \n",
       "\n",
       "      Neutral_Pos  Neutral_Neg  \n",
       "0        0.634112     0.363674  \n",
       "1        0.659470     0.270249  \n",
       "5        0.496957     0.460825  \n",
       "6        0.552564     0.445859  \n",
       "7        0.608680     0.313993  \n",
       "...           ...          ...  \n",
       "1059     0.576933     0.380911  \n",
       "1062     0.670365     0.440210  \n",
       "1064     0.383629     0.614365  \n",
       "1067     0.416400     0.461552  \n",
       "1069     0.378117     0.489754  \n",
       "\n",
       "[448 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'next_day_vector': [1217.51,\n",
       "   1395.839195690751,\n",
       "   25.248018814325256,\n",
       "   0.5,\n",
       "   15.56,\n",
       "   52.54403131,\n",
       "   6.653620352,\n",
       "   1022,\n",
       "   40.80234834,\n",
       "   52.54403131,\n",
       "   27.86822061],\n",
       "  'comp': 'AMZN'},\n",
       " {'next_day_vector': [87.66,\n",
       "   93.4781572419405,\n",
       "   1.5348345750689567,\n",
       "   4.5,\n",
       "   7.8,\n",
       "   39.01581722,\n",
       "   11.42355009,\n",
       "   569,\n",
       "   49.56063269,\n",
       "   41.36386314,\n",
       "   11.42355009],\n",
       "  'comp': 'MSFT'},\n",
       " {'next_day_vector': [173.44,\n",
       "   168.18254580177367,\n",
       "   1.6677195708751704,\n",
       "   7.5,\n",
       "   18.26,\n",
       "   48.41208366,\n",
       "   9.295120062,\n",
       "   1291,\n",
       "   42.29279628,\n",
       "   48.41208366,\n",
       "   17.84049339],\n",
       "  'comp': 'AAPL'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in next_vectors:\n",
    "    scaler = MinMaxScaler()\n",
    "    for dict in scalers_decisions:\n",
    "        if dict['comp'] == i['comp']:\n",
    "            scaler = dict['scaler']\n",
    "            break\n",
    "\n",
    "    array_2d = np.array(i['next_day_vector']).reshape(-1, 1)\n",
    "    normalized_array = scaler.fit_transform(array_2d)\n",
    "    normalized_list = normalized_array.flatten()\n",
    "    i['next_day_vector'] = normalized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'next_day_vector': array([0.87219653, 1.        , 0.0177362 , 0.        , 0.01079307,\n",
       "         0.03729848, 0.00441013, 0.73208006, 0.02888355, 0.03729848,\n",
       "         0.01961403]),\n",
       "  'comp': 'AMZN'},\n",
       " {'next_day_vector': array([0.15177172, 0.16202461, 0.        , 0.00522528, 0.01104062,\n",
       "         0.06604984, 0.01742612, 1.        , 0.08463215, 0.07018762,\n",
       "         0.01742612]),\n",
       "  'comp': 'MSFT'},\n",
       " {'next_day_vector': array([0.13322577, 0.12914811, 0.        , 0.00452349, 0.01286889,\n",
       "         0.03625471, 0.00591578, 1.        , 0.03150862, 0.03625471,\n",
       "         0.01254353]),\n",
       "  'comp': 'AAPL'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarty\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "buy_score = []\n",
    "sell_score = []\n",
    "keep_score = []\n",
    "\n",
    "for i in range(len(next_vectors)):\n",
    "    buy_score_similarity = 0\n",
    "    buy_score_similarity = cosine_similarity(buy_df.values, [next_vectors[i]['next_day_vector']])\n",
    "    total_cos_buy_score = np.average(buy_score_similarity)\n",
    "    buy_score.append({'buyscore': total_cos_buy_score, 'comp': next_vectors[i]['comp']})\n",
    "\n",
    "\n",
    "    sell_score_similarity = 0\n",
    "    sell_score_similarity = cosine_similarity(sell_df.values, [next_vectors[i]['next_day_vector']])\n",
    "\n",
    "    total_cos_sell_score = np.average(sell_score_similarity)\n",
    "    sell_score.append({'sellscore': total_cos_sell_score, 'comp': next_vectors[i]['comp']})\n",
    "\n",
    "    keep_score_similarity = 0\n",
    "    keep_score_similarity = cosine_similarity(keep_df.values, [next_vectors[i]['next_day_vector']])\n",
    "    total_cos_keep_score = np.average(keep_score_similarity)\n",
    "    keep_score.append({'keepscore': total_cos_keep_score, 'comp': next_vectors[i]['comp']})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AMZN': {'buy': 0.41180797369900074, 'sell': 0.45235660090915414, 'keep': 0.43427108852214197}, 'MSFT': {'buy': 0.4424421823412326, 'sell': 0.4562467710696235, 'keep': 0.4623769819122476}, 'AAPL': {'buy': 0.40372258990037996, 'sell': 0.41752737327100914, 'keep': 0.4240967693914231}}\n"
     ]
    }
   ],
   "source": [
    "company_scores = {}\n",
    "\n",
    "# Merge the scores for each company\n",
    "for score_list, score_type in zip([buy_score, sell_score, keep_score], ['buy', 'sell', 'keep']):\n",
    "    for score in score_list:\n",
    "        comp = score['comp']\n",
    "        score_value = score[score_type + 'score']\n",
    "        if comp not in company_scores:\n",
    "            company_scores[comp] = {'buy': None, 'sell': None, 'keep': None}\n",
    "        company_scores[comp][score_type] = score_value\n",
    "\n",
    "print(company_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy Stocks: []\n",
      "Sell Stocks: ['AMZN']\n",
      "Keep Stocks: ['MSFT', 'AAPL']\n"
     ]
    }
   ],
   "source": [
    "buy_basket = []\n",
    "sell_basket = []\n",
    "keep_basket = []\n",
    "\n",
    "for company, scores in company_scores.items():\n",
    "    buy_score = scores['buy']\n",
    "    sell_score = scores['sell']\n",
    "    keep_score = scores['keep']\n",
    "\n",
    "    if buy_score is not None and (sell_score is None or buy_score > sell_score) and (keep_score is None or buy_score > keep_score):\n",
    "        buy_basket.append(company)\n",
    "    elif sell_score is not None and (buy_score is None or sell_score > buy_score) and (keep_score is None or sell_score > keep_score):\n",
    "        sell_basket.append(company)\n",
    "    elif keep_score is not None and (buy_score is None or keep_score > buy_score) and (sell_score is None or keep_score > sell_score):\n",
    "        keep_basket.append(company)\n",
    "\n",
    "print(\"Buy Stocks:\", buy_basket)\n",
    "print(\"Sell Stocks:\", sell_basket)\n",
    "print(\"Keep Stocks:\", keep_basket)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
